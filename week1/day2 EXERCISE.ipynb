{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d15d8294-3328-4e07-ad16-8a03e9bbfdb9",
   "metadata": {},
   "source": [
    "# Welcome to your first assignment!\n",
    "\n",
    "Instructions are below. Please give this a try, and look in the solutions folder if you get stuck (or feel free to ask me!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada885d9-4d42-4d9b-97f0-74fbbbfe93a9",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../resources.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#f71;\">Just before we get to the assignment --</h2>\n",
    "            <span style=\"color:#f71;\">I thought I'd take a second to point you at this page of useful resources for the course. This includes links to all the slides.<br/>\n",
    "            <a href=\"https://edwarddonner.com/2024/11/13/llm-engineering-resources/\">https://edwarddonner.com/2024/11/13/llm-engineering-resources/</a><br/>\n",
    "            Please keep this bookmarked, and I'll continue to add more useful links there over time.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9fa1fc-eac5-4d1d-9be4-541b3f2b3458",
   "metadata": {},
   "source": [
    "# HOMEWORK EXERCISE ASSIGNMENT\n",
    "\n",
    "Upgrade the day 1 project to summarize a webpage to use an Open Source model running locally via Ollama rather than OpenAI\n",
    "\n",
    "You'll be able to use this technique for all subsequent projects if you'd prefer not to use paid APIs.\n",
    "\n",
    "**Benefits:**\n",
    "1. No API charges - open-source\n",
    "2. Data doesn't leave your box\n",
    "\n",
    "**Disadvantages:**\n",
    "1. Significantly less power than Frontier Model\n",
    "\n",
    "## Recap on installation of Ollama\n",
    "\n",
    "Simply visit [ollama.com](https://ollama.com) and install!\n",
    "\n",
    "Once complete, the ollama server should already be running locally.  \n",
    "If you visit:  \n",
    "[http://localhost:11434/](http://localhost:11434/)\n",
    "\n",
    "You should see the message `Ollama is running`.  \n",
    "\n",
    "If not, bring up a new Terminal (Mac) or Powershell (Windows) and enter `ollama serve`  \n",
    "And in another Terminal (Mac) or Powershell (Windows), enter `ollama pull llama3.2`  \n",
    "Then try [http://localhost:11434/](http://localhost:11434/) again.\n",
    "\n",
    "If Ollama is slow on your machine, try using `llama3.2:1b` as an alternative. Run `ollama pull llama3.2:1b` from a Terminal or Powershell, and change the code below from `MODEL = \"llama3.2\"` to `MODEL = \"llama3.2:1b\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e2a9393-7767-488e-a8bf-27c12dca35bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29ddd15d-a3c5-4f4e-a678-873f56162724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a512e95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e74a3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"llama3.2:1b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dac0a679-599c-441f-9bf2-ddc73d35b940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a messages list using the same format that we used for OpenAI\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Describe some of the business applications of Generative AI\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bb9c624-14f0-4945-a719-8ddb64f66f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": False\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "479ff514-e8bd-4985-a572-2ea28bb4fa40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ollama' �����ڲ����ⲿ���Ҳ���ǿ����еĳ���\n",
      "���������ļ���\n"
     ]
    }
   ],
   "source": [
    "# Let's just make sure the model is loaded\n",
    "\n",
    "!ollama pull llama3.2:1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e96b635",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ollama' �����ڲ����ⲿ���Ҳ���ǿ����еĳ���\n",
      "���������ļ���\n"
     ]
    }
   ],
   "source": [
    "!ollama pull deepseek-r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42b9f644-522d-4e05-a691-56e7658c0ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI, also known as artificial general intelligence (AGI), has significant potential to transform various industries and aspects of business. Here are some examples of business applications:\n",
      "\n",
      "1. **Content Generation**: Generative AI can create high-quality content such as articles, social media posts, product descriptions, and even entire books. This could be particularly useful for businesses that need high-volume content creation.\n",
      "2. **Virtual Assistants**: Chatbots powered by generative AI can provide 24/7 customer support, answer frequently asked questions, and perform tasks like email management and data entry.\n",
      "3. **Predictive Maintenance**: Generative AI-powered predictive models can analyze sensor data from machines to predict maintenance needs, reducing downtime and increasing overall efficiency.\n",
      "4. **Design Automation**: Generative AI can generate product designs, prototypes, and even entire product lines based on customer feedback and market trends.\n",
      "5. **Marketing Personalization**: By analyzing customer data and using generative AI, businesses can create personalized marketing campaigns that resonate with individual customers.\n",
      "6. **Quality Control**: Generative AI can analyze images, videos, or audio files to detect defects, inconsistencies, or anomalies, helping businesses improve product quality and reduce waste.\n",
      "7. **Medical Imaging Analysis**: Generative AI can analyze medical images like X-rays, MRIs, or CT scans to help doctors diagnose diseases more accurately and quickly.\n",
      "8. **Supply Chain Optimization**: By analyzing historical data and using generative AI, businesses can optimize their supply chain operations, reducing costs and improving delivery times.\n",
      "9. **Cybersecurity Threat Detection**: Generative AI can analyze network traffic, system logs, or other security data to identify potential threats and alert teams of suspicious activity.\n",
      "10. **Education Personalization**: Generative AI-powered adaptive learning systems can tailor educational content to individual students' needs, abilities, and learning styles.\n",
      "11. **Customer Service Chatbots**: As chatbots become more advanced, they may use generative AI to respond to customer inquiries, provide support, and even resolve issues in real-time.\n",
      "12. **Marketing Research**: Generative AI can analyze large datasets to identify patterns, trends, and insights that inform business decisions.\n",
      "13. **Product Idea Generation**: Generative AI-powered brainstorming tools can help businesses generate new product ideas, prototypes, or even entire product lines based on customer feedback and market trends.\n",
      "14. **Financial Modeling**: By analyzing historical data and using generative AI, businesses can create complex financial models to predict future performance, identify potential risks, and optimize investment strategies.\n",
      "15. **Auditing and Compliance**: Generative AI can analyze audit logs, financial statements, or other regulatory documents to detect potential compliance issues and ensure business operations are in line with laws and regulations.\n",
      "\n",
      "These are just a few examples of the many ways generative AI is transforming various aspects of business. As this technology continues to evolve, we can expect to see even more innovative applications across industries.\n"
     ]
    }
   ],
   "source": [
    "# If this doesn't work for any reason, try the 2 versions in the following cells\n",
    "# And double check the instructions in the 'Recap on installation of Ollama' at the top of this lab\n",
    "# And if none of that works - contact me!\n",
    "\n",
    "response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)\n",
    "print(response.json()['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a021f13-d6a1-4b96-8e18-4eae49d876fe",
   "metadata": {},
   "source": [
    "# Introducing the ollama package\n",
    "\n",
    "And now we'll do the same thing, but using the elegant ollama python package instead of a direct HTTP call.\n",
    "\n",
    "Under the hood, it's making the same call as above to the ollama server running at localhost:11434"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7745b9c4-57dc-4867-9180-61fa5db55eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries. Here are some examples:\n",
      "\n",
      "1. **Content Creation**: Generative AI can help businesses create high-quality content, such as blog posts, social media posts, product descriptions, and even entire websites, at scale and with minimal human intervention. This can save time, reduce costs, and improve the overall user experience.\n",
      "\n",
      "2. **Marketing Automation**: Generative AI can assist in creating personalized marketing messages, lead magnets, and automated email campaigns, enabling businesses to personalize their interactions with customers more effectively.\n",
      "\n",
      "3. **Customer Service Chatbots**: Generative AI-powered chatbots can respond to customer inquiries, provide basic support, and route complex issues to human representatives, increasing first-call resolution rates and reducing the workload for customer service teams.\n",
      "\n",
      "4. **Product Development**: Generative AI can help designers create new product ideas, prototypes, and even entire products from scratch, accelerating time-to-market and improving innovation.\n",
      "\n",
      "5. **Predictive Maintenance**: Generative AI can analyze sensor data and predict equipment failures, allowing businesses to schedule maintenance before issues arise, reducing downtime and increasing overall efficiency.\n",
      "\n",
      "6. **Personalized Recommendations**: Generative AI can help businesses create targeted product recommendations for customers based on their browsing and purchasing history, improving customer engagement and driving sales.\n",
      "\n",
      "7. **Automated Content Optimization**: Generative AI can analyze website content and suggest improvements to increase conversions, improve user experience, and enhance search engine rankings.\n",
      "\n",
      "8. **Employee Training**: Generative AI can help businesses create interactive training modules for employees, reducing the need for physical training facilities and improving knowledge retention.\n",
      "\n",
      "9. **Sales Proposal Generation**: Generative AI can assist sales teams in creating personalized sales proposals by analyzing customer data and generating tailored offers.\n",
      "\n",
      "10. **Supply Chain Optimization**: Generative AI can analyze supply chain data to predict potential issues, optimize inventory levels, and reduce waste, helping businesses streamline their operations and improve efficiency.\n",
      "\n",
      "11. **Quality Control**: Generative AI can help businesses inspect products for defects, detect anomalies, and identify areas for improvement, reducing the need for manual inspection and improving product quality.\n",
      "\n",
      "12. **Financial Analysis**: Generative AI can analyze large datasets to identify trends, patterns, and insights that may inform business decisions, such as predicting market fluctuations or identifying new business opportunities.\n",
      "\n",
      "These are just a few examples of the many business applications of Generative AI. As the technology continues to evolve, we can expect to see even more innovative uses in various industries.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(model=MODEL, messages=messages)\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4704e10-f5fb-4c15-a935-f046c06fb13d",
   "metadata": {},
   "source": [
    "## Alternative approach - using OpenAI python library to connect to Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23057e00-b6fc-4678-93a9-6b31cb704bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has a wide range of business applications across various industries. Here are some examples:\n",
      "\n",
      "1. **Content Creation**: Generative AI can be used to create high-quality, automated content such as:\n",
      "\t* News articles: AI can analyze large amounts of data and generate news headlines, summaries, and even entire articles.\n",
      "\t* Social media posts: AI can craft engaging social media content, including ads, blog posts, and comments.\n",
      "\t* E-books and guides: AI can help authors create long-form content, such as ebooks, PDF guides, and whitepapers.\n",
      "2. **Virtual Products and Services**: Generative AI can be used to create immersive experiences, such as:\n",
      "\t* Virtual concerts and events: AI-powered avatars can interact with attendees in virtual environments.\n",
      "\t* Virtual reality (VR) and augmented reality (AR) experiences: AI can generate customized 3D environments for users.\n",
      "\t* Personalized customer service: AI-powered chatbots can provide individuals with tailored responses to their queries.\n",
      "3. **Marketing and Advertising**: Generative AI can be used to:\n",
      "\t* Generate creative asset ideas: AI can brainstorm new concept ideas for marketing campaigns, social media ads, or email promotions.\n",
      "\t* Personalize targeting: AI can analyze customer behavior data and generate targeted content based on individual preferences.\n",
      "\t* Optimize ad messaging: AI can help optimize ad creatives based on audience behavior and interests.\n",
      "4. **Healthcare**: Generative AI can be used to:\n",
      "\t* Create medical models: AI can generate 3D anatomical models of the human body for surgical planning and training.\n",
      "\t* Generate personalized treatment plans: AI can analyze genetic data, medical history, and lifestyle factors to create tailored treatment strategies.\n",
      "\t* Process medical images: AI can help doctors identify potential diagnoses from radiological images.\n",
      "5. **E-commerce**: Generative AI can be used to:\n",
      "\t* Curate product recommendations: AI can analyze customer purchases and behavior data to suggest new products for checkout.\n",
      "\t* Automate inventory management: AI can optimize inventory levels based on historical sales data and expected churn.\n",
      "\t* Enhance chatbots: AI-powered chatbots can provide personalized product recommendations, promotions, and support.\n",
      "6. **Education**: Generative AI can be used to:\n",
      "\t* Create interactive learning materials: AI-powered simulations and games can teach complex concepts in an engaging way.\n",
      "\t* Personalize student outcomes: AI can analyze learning data and adjust instruction for individual students based on performance.\n",
      "\t* Automate grading: AI can review graded assignments, identifying areas where students may need additional support.\n",
      "\n",
      "These are just a few examples of the many business applications of Generative AI. As the technology continues to evolve, we can expect to see even more innovative uses across various industries.\n"
     ]
    }
   ],
   "source": [
    "# There's actually an alternative approach that some people might prefer\n",
    "# You can use the OpenAI client python library to call Ollama:\n",
    "\n",
    "from openai import OpenAI\n",
    "ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9e22da-b891-41f6-9ac9-bd0c0a5f4f44",
   "metadata": {},
   "source": [
    "## Are you confused about why that works?\n",
    "\n",
    "It seems strange, right? We just used OpenAI code to call Ollama?? What's going on?!\n",
    "\n",
    "Here's the scoop:\n",
    "\n",
    "The python class `OpenAI` is simply code written by OpenAI engineers that makes calls over the internet to an endpoint.  \n",
    "\n",
    "When you call `openai.chat.completions.create()`, this python code just makes a web request to the following url: \"https://api.openai.com/v1/chat/completions\"\n",
    "\n",
    "Code like this is known as a \"client library\" - it's just wrapper code that runs on your machine to make web requests. The actual power of GPT is running on OpenAI's cloud behind this API, not on your computer!\n",
    "\n",
    "OpenAI was so popular, that lots of other AI providers provided identical web endpoints, so you could use the same approach.\n",
    "\n",
    "So Ollama has an endpoint running on your local box at http://localhost:11434/v1/chat/completions  \n",
    "And in week 2 we'll discover that lots of other providers do this too, including Gemini and DeepSeek.\n",
    "\n",
    "And then the team at OpenAI had a great idea: they can extend their client library so you can specify a different 'base url', and use their library to call any compatible API.\n",
    "\n",
    "That's it!\n",
    "\n",
    "So when you say: `ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')`  \n",
    "Then this will make the same endpoint calls, but to Ollama instead of OpenAI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7d1de3-e2ac-46ff-a302-3b4ba38c4c90",
   "metadata": {},
   "source": [
    "## Also trying the amazing reasoning model DeepSeek\n",
    "\n",
    "Here we use the version of DeepSeek-reasoner that's been distilled to 1.5B.  \n",
    "This is actually a 1.5B variant of Qwen that has been fine-tuned using synethic data generated by Deepseek R1.\n",
    "\n",
    "Other sizes of DeepSeek are [here](https://ollama.com/library/deepseek-r1) all the way up to the full 671B parameter version, which would use up 404GB of your drive and is far too large for most!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf9eb44e-fe5b-47aa-b719-0bb63669ab3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling aabd4debf0c8: 100% ▕██████████████████▏ 1.1 GB                         \u001b[K\n",
      "pulling c5ad996bda6e: 100% ▕██████████████████▏  556 B                         \u001b[K\n",
      "pulling 6e4c38e1172f: 100% ▕██████████████████▏ 1.1 KB                         \u001b[K\n",
      "pulling f4d24e9138dd: 100% ▕██████████████████▏  148 B                         \u001b[K\n",
      "pulling a85fe2a2e58e: 100% ▕██████████████████▏  487 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "!ollama pull deepseek-r1:1.5b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d3d554b-e00d-4c08-9300-45e073950a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so I need to figure out the definitions of three key LLM concepts: Neural Network, Attention, and Transformer. Let me start by thinking about what each term means individually before they combine.\n",
      "\n",
      "First, Neural Network. From what I remember, a neural network is like that biological brain in our brains, right? People have these networks that allow them to think abstractly. So, for a computer, a neural network must be some kind of system similar to the human brain. It has layers with neurons connected between them. These layers process information and produce outputs. But how does this apply specifically to AI models?\n",
      "\n",
      "Hmm, so maybe a neural network is made up of interconnected nodes or \"neurons\" that can take in inputs, process them, and output an activation or decision. They learn through examples, which I guess means they can adapt to different tasks.\n",
      "\n",
      "Okay, now attention. I've heard the word \"attention\" used a lot when talking about transformers. But what does it actually mean? It's vague to me. So maybe in the context of LLMs and Transformers, attention refers to how the model prioritizes or weighs different parts of its input data.\n",
      "\n",
      "There are probably multiple layers of attention processing. Maybe lower levels focus on local features, like short-term patterns, while higher levels process longer-range dependencies. Also, this must help the model understand relationships between words in a sentence, which is where transformers get their power from too. Transformers use attention mechanisms to weigh sequential information and improve translation.\n",
      "\n",
      "Wait, I'm not sure about that part. How does the transformer specifically use attention for processing sentences? Is it in each word's projection layer or something like that?\n",
      "\n",
      "Then there's the Transformer itself. As a model architecture, what defines a Transformer? It probably has multiple \"layers,\" each with self-attention layers and feed-forward networks that transform the input. The self-attention allows models to pay attention to different positions in a sequence and learn local patterns.\n",
      "\n",
      "I think maybe each position in the sequence can attend to any other position, but this process is applied sequentially through each layer, allowing for the model to capture long-range dependencies by processing outputs of one layer as inputs to another. This self-attention mechanism must be key to the transformer's ability to understand and translate sentences effectively.\n",
      "\n",
      "Putting it together: A neural network in LLMs would consist of layers, nodes, connections, and learn through data. Attention refers to how each part processes its input relative to others. Transformers are a type of architecture that uses the Transformer model, which comprises layers and self-attention mechanisms processing sequential data for tasks like language modeling.\n",
      "\n",
      "I might be mixing up some points here, especially about attention in transformers versus general AI models. Maybe I should think of it more step by step, focusing on each component: what is a neural network's fundamental structure? What's the role of attention within that context? Finally, how do transformers fit into this architecture and utilize those components.\n",
      "\n",
      "Alternatively, are there other concepts related to LLMs besides attention and Transformers? Maybe model size, depth, but the user specifically mentioned attention and Transformers. So maybe I don't need to cover other areas unless it's part of defining them.\n",
      "\n",
      "I should also consider the role of each component in processing tasks. For example, a neural network applies weights to inputs per neuron and produces outputs, possibly with non-linear activations. Attention in transformers allows models to focus on certain tokens or positions, based on their similarity or relevance.\n",
      "\n",
      "Transformers process input sequences by feeding the output from one layer into another while keeping all the intermediate representations in memory. This might be similar to how a neural network works but without explicit weights and perhaps using self-attention during both training and inference.\n",
      "\n",
      "So, structuring my thoughts: I'll first define Neural Network as a biologically inspired computing system with layers and nodes processing information through connections, learning from data. Then attention as the mechanism in Transformers that allows each part of the model to focus on certain parts based on their relevance or proximity. Finally, Transformer as the architecture comprising these components, with self-attention enabling the model's ability to attend to any position relative to others in a sequence.\n",
      "</think>\n",
      "\n",
      "The core concepts behind LLMs, focusing on neural networks, attention, and transformers, are as follows:\n",
      "\n",
      "### Neural Network\n",
      "A neural network is inspired by biological neural systems, designed to mimic human brain functions. It consists of interconnected nodes or neurons that process information through layers, connections, and weights. These networks learn from data, adjusting their internal parameters to perform tasks such as classification and regression. Unlike traditional computing models, LLMs leverage these components for AI tasks.\n",
      "\n",
      "### Attention\n",
      "In the context of LLMs, attention refers to Transformer's mechanism where each layer processes input through self-attention and feed-forward networks. This allows models to weigh nodes by relevance or proximity, enabling their focus on certain parts based on similarity and relevance. Transformers achieve this in both training and inference phases by processing sequential information across layers.\n",
      "\n",
      "### Transformer Architecture\n",
      "The Transformer model is characterized by its architecture comprising multiple layers with self-attention mechanisms. Each layer handles self-attention for local patterns and feed-forward transformations for sequence memory. This setup enables the model to capture long-range dependencies by processing outputs of one layer as inputs to another, essential for tasks like language translation.\n",
      "\n",
      "These components work together within the Transformer architecture, allowing it to perform complex cognitive functions akin to biological networks, processing tasks such as text understanding and reasoning through data.\n"
     ]
    }
   ],
   "source": [
    "# This may take a few minutes to run! You should then see a fascinating \"thinking\" trace inside <think> tags, followed by some decent definitions\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=\"deepseek-r1:1.5b\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Please give definitions of some core concepts behind LLMs: a neural network, attention and the transformer\"}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1622d9bb-5c68-4d4e-9ca4-b492c751f898",
   "metadata": {},
   "source": [
    "# NOW the exercise for you\n",
    "\n",
    "Take the code from day1 and incorporate it here, to build a website summarizer that uses Llama 3.2 running locally instead of OpenAI; use either of the above approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de38216-6d1c-48c4-877b-86d403f4e0f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms_engineering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
